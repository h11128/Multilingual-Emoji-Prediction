{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from codecs import open\n",
    "import sys\n",
    "\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "from scipy import stats\n",
    "import matplotlib\n",
    "matplotlib.use(\"module://mplcairo.qt\")\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina', quality=100)\n",
    "def f1(precision,recall):\n",
    "    return (2.0*precision*recall)/(precision+recall)\n",
    "\n",
    "def main(path_goldstandard, path_outputfile):\n",
    "\n",
    "    truth_dict={}\n",
    "    output_dict_correct={}\n",
    "    output_dict_attempted={}\n",
    "    predicted = {}\n",
    "    correct = 0\n",
    "    truth_file_lines=open(path_goldstandard,encoding='utf8').readlines()\n",
    "    submission_file_lines=open(path_outputfile,encoding='utf8').readlines()\n",
    "    if len(submission_file_lines)!=len(truth_file_lines): sys.exit('ERROR: Number of lines in gold and output files differ')\n",
    "    or_distribution = [0 for _ in range(20)]\n",
    "    pr_distribution = [0 for _ in range(20)]\n",
    "    for i in range(20):\n",
    "        predicted[i] = [0 for _ in range(20)]\n",
    "    for i in range(len(submission_file_lines)):\n",
    "        line = submission_file_lines[i]\n",
    "        emoji_code_gold = truth_file_lines[i]\n",
    "        emoji_code_output=int(submission_file_lines[i].replace(\"\\n\",\"\"))\n",
    "        emoji_code_gold=int(truth_file_lines[i].replace(\"\\n\",\"\"))\n",
    "        if emoji_code_gold == emoji_code_output:\n",
    "            correct += 1\n",
    "        or_distribution[emoji_code_gold] += 1\n",
    "        pr_distribution[emoji_code_output] += 1\n",
    "        \n",
    "        predicted[emoji_code_gold][emoji_code_output] += 1\n",
    "    \n",
    "    for i in range(len(predicted)):\n",
    "        total = sum(predicted[i])\n",
    "        for j in range(len(predicted)):\n",
    "            predicted[i][j] = str(round(predicted[i][j]/total*100,3)) + \"%\"\n",
    "    \n",
    "    return predicted, or_distribution, pr_distribution, correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.29932\n",
      "{0: ['83.932%', '2.436%', '6.566%', '0.315%', '1.584%', '0.232%', '0.241%', '0.482%', '0.0%', '0.009%', '1.445%', '0.333%', '1.009%', '0.0%', '0.065%', '0.157%', '0.0%', '1.176%', '0.019%', '0.0%'], 1: ['75.445%', '5.859%', '10.745%', '0.062%', '2.319%', '0.166%', '0.331%', '0.911%', '0.0%', '0.0%', '1.925%', '0.269%', '1.014%', '0.0%', '0.062%', '0.021%', '0.0%', '0.87%', '0.0%', '0.0%'], 2: ['36.745%', '2.206%', '52.272%', '0.0%', '3.088%', '0.199%', '0.706%', '0.265%', '0.0%', '0.0%', '2.272%', '0.463%', '0.772%', '0.0%', '0.11%', '0.176%', '0.0%', '0.728%', '0.0%', '0.0%'], 3: ['85.758%', '2.303%', '5.489%', '0.422%', '1.42%', '0.115%', '0.192%', '0.806%', '0.0%', '0.0%', '1.536%', '0.154%', '0.883%', '0.0%', '0.038%', '0.115%', '0.0%', '0.768%', '0.0%', '0.0%'], 4: ['36.868%', '2.637%', '19.833%', '0.0%', '31.405%', '0.323%', '0.565%', '1.346%', '0.0%', '0.027%', '4.171%', '0.538%', '1.103%', '0.0%', '0.108%', '0.646%', '0.0%', '0.323%', '0.108%', '0.0%'], 5: ['69.746%', '4.402%', '13.949%', '0.062%', '2.108%', '1.798%', '0.992%', '0.744%', '0.0%', '0.0%', '1.736%', '0.31%', '2.542%', '0.0%', '0.31%', '0.186%', '0.0%', '1.116%', '0.0%', '0.0%'], 6: ['53.858%', '3.357%', '21.393%', '0.05%', '7.365%', '1.353%', '1.854%', '1.353%', '0.0%', '0.0%', '2.655%', '0.601%', '4.509%', '0.0%', '0.251%', '0.501%', '0.0%', '0.752%', '0.15%', '0.0%'], 7: ['66.351%', '3.056%', '9.931%', '0.073%', '5.056%', '0.691%', '0.4%', '5.966%', '0.0%', '0.036%', '3.674%', '0.582%', '1.31%', '0.0%', '0.182%', '0.837%', '0.0%', '1.819%', '0.036%', '0.0%'], 8: ['83.473%', '2.195%', '7.36%', '0.194%', '1.614%', '0.323%', '0.258%', '0.968%', '0.0%', '0.0%', '1.162%', '0.452%', '1.356%', '0.0%', '0.0%', '0.129%', '0.0%', '0.452%', '0.065%', '0.0%'], 9: ['77.702%', '2.723%', '9.787%', '0.511%', '2.809%', '0.596%', '0.34%', '0.596%', '0.0%', '0.085%', '1.447%', '0.426%', '1.362%', '0.0%', '0.255%', '0.17%', '0.0%', '1.191%', '0.0%', '0.0%'], 10: ['35.824%', '1.536%', '11.802%', '0.0%', '4.33%', '0.279%', '0.419%', '1.117%', '0.0%', '0.0%', '41.76%', '0.279%', '0.908%', '0.0%', '0.14%', '0.419%', '0.0%', '0.978%', '0.209%', '0.0%'], 11: ['71.78%', '1.847%', '7.029%', '0.103%', '3.284%', '0.359%', '0.564%', '0.77%', '0.0%', '0.0%', '2.463%', '8.415%', '2.206%', '0.0%', '0.154%', '0.257%', '0.0%', '0.718%', '0.051%', '0.0%'], 12: ['59.051%', '2.609%', '7.668%', '0.158%', '2.609%', '0.711%', '1.265%', '1.581%', '0.0%', '0.0%', '2.451%', '0.395%', '21.028%', '0.0%', '0.079%', '0.079%', '0.0%', '0.316%', '0.0%', '0.0%'], 13: ['82.496%', '3.411%', '5.925%', '0.269%', '2.693%', '0.18%', '0.18%', '0.898%', '0.0%', '0.0%', '1.436%', '0.718%', '1.167%', '0.0%', '0.18%', '0.09%', '0.0%', '0.359%', '0.0%', '0.0%'], 14: ['52.297%', '3.982%', '30.398%', '0.0%', '2.603%', '1.072%', '1.455%', '1.991%', '0.0%', '0.0%', '2.067%', '0.383%', '1.455%', '0.0%', '0.613%', '0.613%', '0.0%', '0.842%', '0.23%', '0.0%'], 15: ['51.527%', '1.125%', '26.768%', '0.0%', '10.209%', '0.482%', '0.884%', '0.804%', '0.0%', '0.0%', '2.814%', '0.563%', '1.045%', '0.0%', '0.161%', '3.457%', '0.0%', '0.161%', '0.0%', '0.0%'], 16: ['57.849%', '4.597%', '24.545%', '0.0%', '3.729%', '1.474%', '0.781%', '1.041%', '0.0%', '0.173%', '2.168%', '0.52%', '0.954%', '0.0%', '0.173%', '0.173%', '0.0%', '1.735%', '0.087%', '0.0%'], 17: ['39.353%', '1.618%', '5.178%', '0.0%', '0.906%', '0.518%', '0.065%', '1.424%', '0.0%', '0.0%', '0.971%', '0.259%', '0.712%', '0.0%', '0.129%', '0.0%', '0.0%', '48.867%', '0.0%', '0.0%'], 18: ['32.354%', '1.614%', '12.536%', '0.0%', '5.627%', '0.29%', '0.248%', '1.117%', '0.0%', '0.0%', '43.484%', '0.414%', '0.91%', '0.0%', '0.207%', '0.496%', '0.0%', '0.414%', '0.29%', '0.0%'], 19: ['49.01%', '3.564%', '34.554%', '0.0%', '4.653%', '0.693%', '0.891%', '0.792%', '0.0%', '0.099%', '1.386%', '0.792%', '1.287%', '0.0%', '0.495%', '0.891%', '0.0%', '0.891%', '0.0%', '0.0%']}\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "path_goldstandard = \"gold.labels\"\n",
    "path_outputfile = \"predictions.txt\"\n",
    "predicted_distribution, or_distribution, pr_distribution, correct = main(path_goldstandard, path_outputfile)\n",
    "print(\"accuracy: \" + str(correct/sum(or_distribution)))\n",
    "print(predicted_distribution)\n",
    "print(sum(or_distribution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['â¤', '_red_heart_'], 1: ['ğŸ˜', '_smiling_face_with_hearteyes_'], 2: ['ğŸ˜‚', '_face_with_tears_of_joy_'], 3: ['ğŸ’•', '_two_hearts_'], 4: ['ğŸ”¥', '_fire_'], 5: ['ğŸ˜Š', '_smiling_face_with_smiling_eyes_'], 6: ['ğŸ˜', '_smiling_face_with_sunglasses_'], 7: ['âœ¨', '_sparkles_'], 8: ['ğŸ’™', '_blue_heart_'], 9: ['ğŸ˜˜', '_face_blowing_a_kiss_'], 10: ['ğŸ“·', '_camera_'], 11: ['ğŸ‡ºğŸ‡¸', '_United_States_'], 12: ['â˜€', '_sun_'], 13: ['ğŸ’œ', '_purple_heart_'], 14: ['ğŸ˜‰', '_winking_face_'], 15: ['ğŸ’¯', '_hundred_points_'], 16: ['ğŸ˜', '_beaming_face_with_smiling_eyes_'], 17: ['ğŸ„', '_Christmas_tree_'], 18: ['ğŸ“¸', '_camera_with_flash_'], 19: ['ğŸ˜œ', '_winking_face_with_tongue_']}\n",
      "['â¤', 'ğŸ˜', 'ğŸ˜‚', 'ğŸ’•', 'ğŸ”¥', 'ğŸ˜Š', 'ğŸ˜', 'âœ¨', 'ğŸ’™', 'ğŸ˜˜', 'ğŸ“·', 'ğŸ‡ºğŸ‡¸', 'â˜€', 'ğŸ’œ', 'ğŸ˜‰', 'ğŸ’¯', 'ğŸ˜', 'ğŸ„', 'ğŸ“¸', 'ğŸ˜œ']\n"
     ]
    }
   ],
   "source": [
    "mapping_lines=open(\"us_mapping.txt\",encoding='utf8').readlines()\n",
    "mapping  = {}\n",
    "emoji = []\n",
    "emoji_text = []\n",
    "for line in mapping_lines:\n",
    "    temp = line.strip(\"\\n\").strip(\" \").strip(\"_\").split(\"\\t\")\n",
    "    mapping[int(temp[0])] = [temp[1], temp[2]]\n",
    "print(mapping)\n",
    "\n",
    "for i in range(len(mapping)):\n",
    "    emoji.append(mapping[i][0])\n",
    "    emoji_text.append(mapping[i][1])\n",
    "print(emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "font_path = matplotlib.font_manager.findSystemFonts(fontpaths=None, fontext='ttf')\n",
    "path = \"\"\n",
    "for i in font_path:\n",
    "    if \"seguiemj\" in i:\n",
    "        path = i\n",
    "\n",
    "myfont = FontProperties(fname=path,size=15)\n",
    "flist = [f.name for f in matplotlib.font_manager.fontManager.ttflist]\n",
    "font = matplotlib.font_manager.FontProperties(family='Segoe UI Emoji')\n",
    "file = matplotlib.font_manager.findfont(font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.table.Table at 0x1e64e4fe408>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predicted_list =[]\n",
    "for i in range(20):\n",
    "    predicted_list.append(predicted_distribution[i])\n",
    "'''Function for displaying histogram of variable.'''\n",
    "def table(variable, labels):\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = (8, 5)\n",
    "    plt.rc('font', family='Segoe UI Emoji')\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.patch.set_visible(False)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "    the_table = ax.table(cellText=variable,\n",
    "                      rowLabels=labels,\n",
    "                      colLabels=labels,\n",
    "                      loc='center',\n",
    "                    cellLoc='center')\n",
    "    \n",
    "    prop = FontProperties(fname=file)\n",
    "    #ax.set_xticklabels(emoji, fontproperties=prop, fontsize = 30)\n",
    "    # Make the chart fill out the figure better.\n",
    "    the_table.auto_set_font_size(False)\n",
    "    the_table.set_fontsize(15)\n",
    "    the_table.scale(1, 1) \n",
    "    \n",
    "    #plt.tight_layout()\n",
    "    #plt.savefig(savename, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return the_table\n",
    "table(predicted_list,emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['431.5', '1049.4', '799.6', '2149.8', '917.9'], ['292.2', '717.8', '456.4', '1368.5', '865.6'], ['213.8', '636.0', '305.7', '1175.2', '796.0'], ['124.6', '555.4', '153.2', '677.2', '192.5'], ['66.4', '174.3', '75.1', '577.9', '32.0']]\n",
      "{0: ['83.932%', '2.436%', '6.566%', '0.315%', '1.584%', '0.232%', '0.241%', '0.482%', '0.0%', '0.009%', '1.445%', '0.333%', '1.009%', '0.0%', '0.065%', '0.157%', '0.0%', '1.176%', '0.019%', '0.0%'], 1: ['75.445%', '5.859%', '10.745%', '0.062%', '2.319%', '0.166%', '0.331%', '0.911%', '0.0%', '0.0%', '1.925%', '0.269%', '1.014%', '0.0%', '0.062%', '0.021%', '0.0%', '0.87%', '0.0%', '0.0%'], 2: ['36.745%', '2.206%', '52.272%', '0.0%', '3.088%', '0.199%', '0.706%', '0.265%', '0.0%', '0.0%', '2.272%', '0.463%', '0.772%', '0.0%', '0.11%', '0.176%', '0.0%', '0.728%', '0.0%', '0.0%'], 3: ['85.758%', '2.303%', '5.489%', '0.422%', '1.42%', '0.115%', '0.192%', '0.806%', '0.0%', '0.0%', '1.536%', '0.154%', '0.883%', '0.0%', '0.038%', '0.115%', '0.0%', '0.768%', '0.0%', '0.0%'], 4: ['36.868%', '2.637%', '19.833%', '0.0%', '31.405%', '0.323%', '0.565%', '1.346%', '0.0%', '0.027%', '4.171%', '0.538%', '1.103%', '0.0%', '0.108%', '0.646%', '0.0%', '0.323%', '0.108%', '0.0%'], 5: ['69.746%', '4.402%', '13.949%', '0.062%', '2.108%', '1.798%', '0.992%', '0.744%', '0.0%', '0.0%', '1.736%', '0.31%', '2.542%', '0.0%', '0.31%', '0.186%', '0.0%', '1.116%', '0.0%', '0.0%'], 6: ['53.858%', '3.357%', '21.393%', '0.05%', '7.365%', '1.353%', '1.854%', '1.353%', '0.0%', '0.0%', '2.655%', '0.601%', '4.509%', '0.0%', '0.251%', '0.501%', '0.0%', '0.752%', '0.15%', '0.0%'], 7: ['66.351%', '3.056%', '9.931%', '0.073%', '5.056%', '0.691%', '0.4%', '5.966%', '0.0%', '0.036%', '3.674%', '0.582%', '1.31%', '0.0%', '0.182%', '0.837%', '0.0%', '1.819%', '0.036%', '0.0%'], 8: ['83.473%', '2.195%', '7.36%', '0.194%', '1.614%', '0.323%', '0.258%', '0.968%', '0.0%', '0.0%', '1.162%', '0.452%', '1.356%', '0.0%', '0.0%', '0.129%', '0.0%', '0.452%', '0.065%', '0.0%'], 9: ['77.702%', '2.723%', '9.787%', '0.511%', '2.809%', '0.596%', '0.34%', '0.596%', '0.0%', '0.085%', '1.447%', '0.426%', '1.362%', '0.0%', '0.255%', '0.17%', '0.0%', '1.191%', '0.0%', '0.0%'], 10: ['35.824%', '1.536%', '11.802%', '0.0%', '4.33%', '0.279%', '0.419%', '1.117%', '0.0%', '0.0%', '41.76%', '0.279%', '0.908%', '0.0%', '0.14%', '0.419%', '0.0%', '0.978%', '0.209%', '0.0%'], 11: ['71.78%', '1.847%', '7.029%', '0.103%', '3.284%', '0.359%', '0.564%', '0.77%', '0.0%', '0.0%', '2.463%', '8.415%', '2.206%', '0.0%', '0.154%', '0.257%', '0.0%', '0.718%', '0.051%', '0.0%'], 12: ['59.051%', '2.609%', '7.668%', '0.158%', '2.609%', '0.711%', '1.265%', '1.581%', '0.0%', '0.0%', '2.451%', '0.395%', '21.028%', '0.0%', '0.079%', '0.079%', '0.0%', '0.316%', '0.0%', '0.0%'], 13: ['82.496%', '3.411%', '5.925%', '0.269%', '2.693%', '0.18%', '0.18%', '0.898%', '0.0%', '0.0%', '1.436%', '0.718%', '1.167%', '0.0%', '0.18%', '0.09%', '0.0%', '0.359%', '0.0%', '0.0%'], 14: ['52.297%', '3.982%', '30.398%', '0.0%', '2.603%', '1.072%', '1.455%', '1.991%', '0.0%', '0.0%', '2.067%', '0.383%', '1.455%', '0.0%', '0.613%', '0.613%', '0.0%', '0.842%', '0.23%', '0.0%'], 15: ['51.527%', '1.125%', '26.768%', '0.0%', '10.209%', '0.482%', '0.884%', '0.804%', '0.0%', '0.0%', '2.814%', '0.563%', '1.045%', '0.0%', '0.161%', '3.457%', '0.0%', '0.161%', '0.0%', '0.0%'], 16: ['57.849%', '4.597%', '24.545%', '0.0%', '3.729%', '1.474%', '0.781%', '1.041%', '0.0%', '0.173%', '2.168%', '0.52%', '0.954%', '0.0%', '0.173%', '0.173%', '0.0%', '1.735%', '0.087%', '0.0%'], 17: ['39.353%', '1.618%', '5.178%', '0.0%', '0.906%', '0.518%', '0.065%', '1.424%', '0.0%', '0.0%', '0.971%', '0.259%', '0.712%', '0.0%', '0.129%', '0.0%', '0.0%', '48.867%', '0.0%', '0.0%'], 18: ['32.354%', '1.614%', '12.536%', '0.0%', '5.627%', '0.29%', '0.248%', '1.117%', '0.0%', '0.0%', '43.484%', '0.414%', '0.91%', '0.0%', '0.207%', '0.496%', '0.0%', '0.414%', '0.29%', '0.0%'], 19: ['49.01%', '3.564%', '34.554%', '0.0%', '4.653%', '0.693%', '0.891%', '0.792%', '0.0%', '0.099%', '1.386%', '0.792%', '1.287%', '0.0%', '0.495%', '0.891%', '0.0%', '0.891%', '0.0%', '0.0%']}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Function for displaying histogram of variable.'''\n",
    "def histo(variable, x_name, y_name, title, labels, savename):\n",
    "    plt.rcParams['figure.figsize'] = (8, 5)\n",
    "    plt.rc('font', family='Segoe UI Emoji')\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    bar = ax.bar(x=np.arange(len(variable)), \n",
    "            height=variable,\n",
    "            tick_label=emoji\n",
    "    )\n",
    "    prop = FontProperties(fname=file)\n",
    "    ax.set_xticklabels(emoji, fontproperties=prop, fontsize = 30)\n",
    "    # Make the chart fill out the figure better.\n",
    "    \n",
    "    \n",
    "    plt.xlabel('%s' %x_name, fontsize=18)\n",
    "    plt.ylabel('%s' %y_name, fontsize=18)\n",
    "    plt.title('%s' %title, fontsize=35)\n",
    "    \n",
    "    plt.grid(True)\n",
    "    for rect1, label in zip(bar, labels):\n",
    "        height = rect1.get_height()\n",
    "        plt.annotate(\n",
    "            str(rect1.get_height()),\n",
    "            (rect1.get_x() + rect1.get_width()/2, height+5),\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=15,\n",
    "            fontproperties=prop\n",
    "        )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(savename, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return bar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Label Distribution in the testset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = histo(or_distribution, \"emoji\", \"# of tweets\", \"Actual Emoji Distribution\", emoji, \"emojis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"emojis.png\">\n",
    "There are totally 20 labels and 50k tweets. The Label distribution shows that the top 5 highest number of emojis are red_heartâ¤ 10798, smiling_face_with_hearteyes ğŸ˜ 4830, face_with_tears_of_joyğŸ˜‚ 4534, fireğŸ”¥ 3716, sparklesâœ¨ 2749. The least used 3 emojis are face_blowing_a_kissğŸ˜˜ 1175, purple_heartğŸ’œ 1114, winking_face_with_tongueğŸ˜œ 1010.\n",
    "\n",
    "# Prediction distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = histo(pr_distribution, \"emoji\", \"# of tweets\",\"Predicted Emoji Distribution\", emoji, \"pemojis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pemojis.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pie(labels, sizes, index):\n",
    "    \n",
    "    prop = FontProperties(fname=file)\n",
    "    colors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue']\n",
    "    explode = [0 for _ in range(20)]  # explode 1st slice\n",
    "    explode[index] = 1\n",
    "    sorted_index = sorted(range(len(sizes)), key=sizes.__getitem__)[len(sizes)-5:len(sizes)]\n",
    "    print(sorted_index)\n",
    "    for i in sorted_index:\n",
    "        explode[i] = 0.5\n",
    "    explode = tuple(explode)\n",
    "    print(explode)\n",
    "    # Plot\n",
    "    patches, labelss, autopct = plt.pie(sizes, explode=explode, labels=labels, autopct='%1.2f%%', shadow=True,   textprops={'fontsize': 14, 'fontproperties':prop})\n",
    "    for lab in labelss:\n",
    "        lab.set_fontsize(10)\n",
    "    plt.legend(patches, labels, loc=\"best\", prop=prop, fontsize = 30)\n",
    "    plt.axis('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_text = \"us_test.text\"\n",
    "path_labels = \"us_test.labels\"\n",
    "path_predict = \"predictions.txt\"\n",
    "list_text = []\n",
    "list_labels = []\n",
    "label_to_text = {}\n",
    "predict_to_text = {}\n",
    "text_lines=open(path_text,encoding='utf8').readlines()\n",
    "label_lines=open(path_labels,encoding='utf8').readlines()\n",
    "predict_lines=open(path_predict,encoding='utf8').readlines()\n",
    "for i in range(len(label_lines)):\n",
    "    emoji_code=int(label_lines[i].replace(\"\\n\",\"\"))\n",
    "    emoji_predict = int(predict_lines[i].replace(\"\\n\",\"\"))\n",
    "    text = text_lines[i].strip(\"\\n\")\n",
    "    if emoji_code not in label_to_text:\n",
    "        label_to_text[emoji_code] = [text]\n",
    "    else:\n",
    "        label_to_text[emoji_code].append(text)\n",
    "    if emoji_predict not in predict_to_text:\n",
    "        predict_to_text[emoji_predict] = [text]\n",
    "    else:\n",
    "        predict_to_text[emoji_predict].append(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def Donut(labels, sizes, index):\n",
    "    title = \"Predicted Distribution over tweets with acutal emoji \" + labels[i]\n",
    "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(aspect=\"equal\"))\n",
    "    explode = [0 for _ in range(20)]  # explode 1st slice\n",
    "    explode[index] = 0.3\n",
    "    explode = tuple(explode)\n",
    "    prop = FontProperties(fname=file)\n",
    "    patches, labelss, autopct = ax.pie(sizes, labels=labels, wedgeprops=dict(width=0.4), autopct='%1.2f%%', startangle=40, explode=explode, \n",
    "                           textprops={'fontsize': 30, 'fontproperties':prop})\n",
    "    sorted_index = sorted(range(len(sizes)), key=sizes.__getitem__)[len(sizes)-10:len(sizes)]\n",
    "    #print(sorted_index)\n",
    "    \n",
    "    for lab, value in zip(labelss,autopct):\n",
    "        #print(lab)\n",
    "        \n",
    "        label_index = labels.index(lab.get_text())\n",
    "        percent = float(value.get_text().strip(\"%\"))\n",
    "        if (label_index in sorted_index and percent >1) or label_index == index:\n",
    "            lab.set_fontsize(15)\n",
    "        else:\n",
    "            lab.set_text(\" \")\n",
    "            value.set_text(\" \")\n",
    "    plt.title('%s' %title, fontsize=15)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(\"Figure_%d.png\"%(index+1))\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "Donut(emoji, predicted_distribution[i], i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figure_1.png\">\n",
    "<img src=\"Figure_2.png\">\n",
    "<img src=\"Figure_3.png\">\n",
    "<img src=\"Figure_4.png\">\n",
    "<img src=\"Figure_5.png\">\n",
    "<img src=\"Figure_6.png\">\n",
    "<img src=\"Figure_7.png\">\n",
    "<img src=\"Figure_8.png\">\n",
    "<img src=\"Figure_9.png\">\n",
    "<img src=\"Figure_10.png\">\n",
    "<img src=\"Figure_11.png\">\n",
    "<img src=\"Figure_12.png\">\n",
    "<img src=\"Figure_13.png\">\n",
    "<img src=\"Figure_14.png\">\n",
    "<img src=\"Figure_15.png\">\n",
    "<img src=\"Figure_16.png\">\n",
    "<img src=\"Figure_17.png\">\n",
    "<img src=\"Figure_18.png\">\n",
    "<img src=\"Figure_19.png\">\n",
    "<img src=\"Figure_20.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "## Obeservation:\n",
    "â¤ have 83.932% predicted correctly  \n",
    "ğŸ˜ have 5.859% predicted correctly  \n",
    "ğŸ˜‚ have 52.272% predicted correctly  \n",
    "ğŸ’• have 0.422% predicted correctly  \n",
    "ğŸ”¥ have 31.405% predicted correctly  \n",
    "ğŸ˜Š have 1.798% predicted correctly  \n",
    "ğŸ˜ have 1.854% predicted correctly  \n",
    "âœ¨ have 5.966% predicted correctly  \n",
    "ğŸ’™ have 0.0% predicted correctly  \n",
    "ğŸ˜˜ have 0.085% predicted correctly  \n",
    "ğŸ“· have 41.76% predicted correctly  \n",
    "ğŸ‡ºğŸ‡¸ have 8.415% predicted correctly  \n",
    "â˜€ have 21.028% predicted correctly  \n",
    "ğŸ’œ have 0.0% predicted correctly  \n",
    "ğŸ˜‰ have 0.613% predicted correctly  \n",
    "ğŸ’¯ have 3.457% predicted correctly  \n",
    "ğŸ˜ have 0.0% predicted correctly  \n",
    "ğŸ„ have 48.867% predicted correctly  \n",
    "ğŸ“¸ have 0.29% predicted correctly  \n",
    "ğŸ˜œ have 0.0% predicted correctly  \n",
    "\n",
    "For each tweets no matter what emoji at least 30% probability to predict â¤.  \n",
    "\n",
    "For red heart, blue_heart, purple_heart, double_heart, face_blowing_a_kiss, United_Status which are â¤,ğŸ’•,ğŸ’™,ğŸ’œ,ğŸ˜˜,ğŸ‡ºğŸ‡¸ mainly predict â¤ (at least 80 percent, while ğŸ‡ºğŸ‡¸ have 8 percent predict right)\n",
    "\n",
    "For each tweets ğŸ˜‚ is the second emoji that the model tends to predict unconditionally. Especially the model tends to always predict tweets with actual emoji ğŸ˜œ,ğŸ˜,ğŸ˜‰,ğŸ˜˜ to ğŸ˜‚ except the effect of â¤\n",
    "\n",
    "ğŸ˜ have 5.859% predicted correctly which is second highest accuracy among face emojis. \n",
    "\n",
    "For tweets have emoji ğŸ“¸, the model always predict ğŸ“·\n",
    "\n",
    "ğŸ“·,ğŸ„,ğŸ”¥,â˜€ have some higher accuracy (more than 20%), while âœ¨,ğŸ‡ºğŸ‡¸,ğŸ’¯ have relatively low accuracy\n",
    "\n",
    "## Reasoning:\n",
    "\n",
    "The model cares too much about the frequency of emojis.\n",
    "\n",
    "There are no too much context difference between emojis like ğŸ’•,ğŸ’™,ğŸ’œ,ğŸ˜˜ with â¤  \n",
    "\n",
    "There are no too much context difference between emojis like ğŸ˜œ,ğŸ˜,ğŸ˜‰,ğŸ˜˜ with ğŸ˜‚, maybe because they all have meaning like joy, happy, laughin\n",
    "\n",
    "There are no context difference between ğŸ“¸ and ğŸ“·. People only use the two emoji interchangeablely. Nearly no information can show the difference.\n",
    "\n",
    "ğŸ“·,ğŸ„,ğŸ”¥,â˜€ have its special meaning which is shown in the context with some keywords maybe, while âœ¨,ğŸ‡ºğŸ‡¸,ğŸ’¯ don't have strong keywords to show the difference.\n",
    "\n",
    "## Examples support reasoning:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['â¤', 'ğŸ˜', 'ğŸ˜‚', 'ğŸ’•', 'ğŸ”¥', 'ğŸ˜Š', 'ğŸ˜', 'âœ¨', 'ğŸ’™', 'ğŸ˜˜', 'ğŸ“·', 'ğŸ‡ºğŸ‡¸', 'â˜€', 'ğŸ’œ', 'ğŸ˜‰', 'ğŸ’¯', 'ğŸ˜', 'ğŸ„', 'ğŸ“¸', 'ğŸ˜œ']\n",
      "['_red_heart_', '_smiling_face_with_hearteyes_', '_face_with_tears_of_joy_', '_two_hearts_', '_fire_', '_smiling_face_with_smiling_eyes_', '_smiling_face_with_sunglasses_', '_sparkles_', '_blue_heart_', '_face_blowing_a_kiss_', '_camera_', '_United_States_', '_sun_', '_purple_heart_', '_winking_face_', '_hundred_points_', '_beaming_face_with_smiling_eyes_', '_Christmas_tree_', '_camera_with_flash_', '_winking_face_with_tongue_']\n"
     ]
    }
   ],
   "source": [
    "print(emoji)\n",
    "print(emoji_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merry Christmas from Burt Marketing Group. @ Roseburg, Oregon\n",
      "Happy Thanksgiving, ya turkeys... :: jalen.hutchinson @ Thanksgiving's Heroes\n",
      "That Christmas concert was L I T @ Lake Highlands High\n",
      "Drive through the #lights #tgif #weekend #christmastime #friday #lightshow @ Winnebago Park,â€¦\n",
      "Rehearsal clip. Downbeat at 7:30. Come. Merry Christmas. ï¸ #ericadicegliemusic @ St. Jeromeâ€¦\n",
      "Life is good! The holiday cheer is here #nycjunkgirl #holidayparty #holidays #christmasâ€¦\n",
      "White Christmas @ Washington Ave - Memorial, Houston\n",
      "Time to place your bakery Christmas orders Weâ€™ll be making Yule Logs (chocolate cake withâ€¦\n",
      "A fun day finding our perfect Christmas tree! Athena approves #christmastree #decemberâ€¦\n",
      "All I want for Christmas I got @ Annapolis, Maryland\n"
     ]
    }
   ],
   "source": [
    "for i in predict_to_text[17][:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in predict_to_text[17][:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomorrow I'll be at #TheBeatAuction junxioncomplex Check the flyer for more info. @ Theâ€¦\n",
      "~ The world needs more sparkle @user #NYFW ~ @ Skylight Clarkson Sq\n",
      "post show munchies thebeehive_la @ Infinite Energy Center\n",
      "New clients Expires 1/31/18#socialmediamarketing #couponcommunity #hairstyles #hairgoddessâ€¦\n",
      "Pinking of you Be the first to check out our newest cordless lamps #BSGGlowMini at our boothâ€¦\n",
      "Donâ€™t let society tell you how to be. Express yourself proudly @ Hollywood\n",
      "Last minute #IVYLOVE POP-UP TODAY at theskinroom104 in #whittier! See @user for details â€¦\n",
      "A successful night #paradeoflights @ 9NEWS Parade of Lights\n",
      "We're coming up on 2018, the year of #11 if 2017 wasn't everything you expected, 2018 is yourâ€¦\n",
      "Surround yourself with those who make you smile, build you up, and embrace the sunshine @user\n"
     ]
    }
   ],
   "source": [
    "for i in predict_to_text[7][:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polls are closing soon please continue vote for me ï¸ ï¸ ï¸ @ Westâ€¦\n",
      "One short month until we can change the location back to the dirty T @ Naperville, Illinois\n",
      "-Stay tuned!--#startup #2018 #goals #mindset #millionaire #millionairemindestâ€¦\n",
      "Overwatch eSports League coming Januaryâ€™s 10th 2018 â€¢So far there are a total of 12 teamsâ€¦\n",
      "Look like Africa #look #africa #la #california @ Los Angeles,â€¦\n",
      "What could be more American? #4thofjuly #merica #aafnation #america #harleydavidsonâ€¦\n",
      "Do it. Wear it. Work it. Appreciate it. Happy Election Day! @user\n",
      "We are LIVE at the 6th Annual Latino Festival in Timonium, MD!!! #MagentaPrime #BeMagenta â€¦\n",
      "Voting is cool yo #democracy #vote @ Middleburg, Virginia\n",
      "Party like it's 1776 #mericamonday @ Buhlow Lake Recreation Area\n"
     ]
    }
   ],
   "source": [
    "for i in predict_to_text[11][:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what goes up must come down. #dcmetrolife (pc to @user ) @ Washington Metro\n",
      "My boy Phene been holding it down for the #717 #PA @ Harrisburg, Pennsylvania\n",
      "Be yourself, everyone else is taken. #confidence #beyourself @ Lake Travis\n",
      "Let's get your Thrive on! #heartbeat #healthyfood #health #painrelief #mentalclarityâ€¦\n",
      "Knockin' TF out once I touch down @ Frederick Historic District\n",
      "facts @ South Carolina\n",
      "Hustle #SWEATLIFE #weightlifting #fitfam #lifestyle #bodybuilding #lifting #gains #athleteâ€¦\n",
      "Facts be you- nobody built like you never let someone change youâ€¦\n",
      "In order to get better you have to WORK no matter what level your playing on #ffba #hardworkâ€¦\n",
      "falco_tp one of our sound engineers making sure the levels are good #tbt byâ€¦\n"
     ]
    }
   ],
   "source": [
    "for i in predict_to_text[15][:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
